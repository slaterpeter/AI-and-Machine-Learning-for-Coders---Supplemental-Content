{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slaterpeter/AI-and-Machine-Learning-for-Coders---Supplemental-Content/blob/master/insanely_fast_whisper_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper)\n",
        "\n",
        "By VB (https://twitter.com/reach_vb)\n",
        "\n",
        "P.S. Make sure you're on a GPU run-time ğŸ¤—"
      ],
      "metadata": {
        "id": "q0MBgZKbhdII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pipx && apt install python3.11-venv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF-qp-FWJmyD",
        "outputId": "cd5baf14-1b26-4959-a397-947d24d46eee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/78.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  python3.11-venv\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 3,017 kB of archives.\n",
            "After this operation, 3,372 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-venv amd64 3.11.12-1+jammy1 [3,017 kB]\n",
            "Fetched 3,017 kB in 10s (315 kB/s)\n",
            "Selecting previously unselected package python3.11-venv.\n",
            "(Reading database ... 126109 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.11-venv_3.11.12-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11-venv (3.11.12-1+jammy1) ...\n",
            "Setting up python3.11-venv (3.11.12-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipx install insanely-fast-whisper --force --pip-args=\"--ignore-requires-python\""
      ],
      "metadata": {
        "id": "OL02qjkcWexE",
        "outputId": "e715ef61-026c-4147-dc2d-13e262583b17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lcreating virtual environment...\n",
            "creating shared libraries...\n",
            "upgrading shared libraries...\n",
            "installing insanely-fast-whisper...\n",
            "  installed package \u001b[1minsanely-fast-whisper\u001b[0m \u001b[1m0.0.15\u001b[0m, installed using Python 3.11.12\n",
            "  These apps are now globally available\n",
            "    - insanely-fast-whisper\n",
            "âš ï¸  Note: '/root/.local/bin' is not on your PATH environment variable. These\n",
            "    apps will not be globally accessible until your PATH is updated. Run `pipx\n",
            "    ensurepath` to automatically add it, or manually modify your PATH in your\n",
            "    shell's config file (e.g. ~/.bashrc).\n",
            "done! âœ¨ ğŸŒŸ âœ¨\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipx ensurepath"
      ],
      "metadata": {
        "id": "DWPRCtDSmFwh",
        "outputId": "b7aacc0c-0dfd-4274-f59d-12496765545b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lSuccess! Added /root/.local/bin to the PATH environment variable.\n",
            "\n",
            "Consider adding shell completions for pipx. Run 'pipx completions' for\n",
            "instructions.\n",
            "\n",
            "You will need to open a new terminal or re-login for the PATH changes to take\n",
            "effect. Alternatively, you can source your shell's config file with e.g.\n",
            "'source ~/.bashrc'.\n",
            "\n",
            "Otherwise pipx is ready to go! âœ¨ ğŸŒŸ âœ¨\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pipx list"
      ],
      "metadata": {
        "id": "81gXXL4-nmxv",
        "outputId": "981d8621-2e2c-4a22-a08a-d7e69756692e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25lvenvs are in \u001b[1m/root/.local/share/pipx/venvs\u001b[0m\n",
            "apps are exposed on your $PATH at \u001b[1m/root/.local/bin\u001b[0m\n",
            "manual pages are exposed at \u001b[1m/root/.local/share/man\u001b[0m\n",
            "   package \u001b[1minsanely-fast-whisper\u001b[0m \u001b[1m0.0.15\u001b[0m, installed using Python 3.11.12\n",
            "    - insanely-fast-whisper\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "source": [
        "!MPLBACKEND=agg pipx run insanely-fast-whisper --file-name https://huggingface.co/datasets/reach-vb/random-audios/resolve/main/ted_60.wav"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se83zaeBoiWf",
        "outputId": "d72ea636-71f8-4e3d-c537-0aa23573eb29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 1.27k/1.27k [00:00<00:00, 6.31MB/s]\n",
            "model.safetensors: 100% 3.09G/3.09G [00:26<00:00, 117MB/s]\n",
            "generation_config.json: 100% 3.90k/3.90k [00:00<00:00, 32.8MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 11.2MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 29.9MB/s]\n",
            "tokenizer.json: 100% 2.48M/2.48M [00:00<00:00, 6.83MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 25.5MB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 214MB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 182MB/s]\n",
            "special_tokens_map.json: 100% 2.07k/2.07k [00:00<00:00, 16.4MB/s]\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 2.68MB/s]\n",
            "Device set to use cuda:0\n",
            "\u001b[2K/root/.cache/pipx/d3233dd4c400bc4/lib/python3.11/site-packages/transformers/mode\n",
            "ls/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is \n",
            "deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "ğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:01\u001b[0mYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "\u001b[2KğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:02\u001b[0mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[2KğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:18\u001b[0m\n",
            "\u001b[?25hVoila!âœ¨ Your file has been transcribed go check it out over here ğŸ‘‰ output.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head output.json"
      ],
      "metadata": {
        "id": "BF_dkD9yo1TA",
        "outputId": "35c7d502-195e-4590-8adc-410312a35f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"speakers\": [], \"chunks\": [{\"timestamp\": [0.0, 46.0], \"text\": \" So in college, I was a government major, which means I had to write a lot of papers. Now, when a normal student writes a paper, they might spread the work out a little like this. So, you know, you get started maybe a little slowly, but you get enough done in the first week that with some heavier days later on, everything gets done and things stay civil. And I would want to do that like that. That would be the plan. I would have it all ready to go, but then actually the paper would come along, and then I would kind of do this. And that would happen to every single paper. But then came my 90-page senior thesis, a paper you're supposed to spend a year on.\"}, {\"timestamp\": [46.0, 50.0], \"text\": \" I knew for a paper like that, my normal workflow was not an option.\"}, {\"timestamp\": [50.0, 52.0], \"text\": \" It was way too big a project.\"}, {\"timestamp\": [52.0, 56.0], \"text\": \" So I planned things out, and I decided it kind of had to go something like this.\"}, {\"timestamp\": [56.0, 58.0], \"text\": \" This is how the year would go.\"}, {\"timestamp\": [58.0, 60.0], \"text\": \" So I'd start off light,\"}], \"text\": \" So in college, I was a government major, which means I had to write a lot of papers. Now, when a normal student writes a paper, they might spread the work out a little like this. So, you know, you get started maybe a little slowly, but you get enough done in the first week that with some heavier days later on, everything gets done and things stay civil. And I would want to do that like that. That would be the plan. I would have it all ready to go, but then actually the paper would come along, and then I would kind of do this. And that would happen to every single paper. But then came my 90-page senior thesis, a paper you're supposed to spend a year on. I knew for a paper like that, my normal workflow was not an option. It was way too big a project. So I planned things out, and I decided it kind of had to go something like this. This is how the year would go. So I'd start off light,\"}"
          ]
        }
      ]
    },
    {
      "source": [
        "!MPLBACKEND=agg pipx run insanely-fast-whisper --file-name /content/sample_data/teste.mp3"
      ],
      "cell_type": "code",
      "metadata": {
        "outputId": "64f9adab-4b7b-41f7-b330-47c24c5e3226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SUAHTIIqFh2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\u001b[?25hDevice set to use cuda:0\n",
            "\u001b[2K/root/.cache/pipx/d3233dd4c400bc4/lib/python3.11/site-packages/transformers/mode\n",
            "ls/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is \n",
            "deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "ğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:00\u001b[0mYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "\u001b[2KğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[33m0:00:01\u001b[0mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[2KğŸ¤— \u001b[33mTranscribing...\u001b[0m \u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[37mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m\u001b[93mâ”\u001b[0m \u001b[33m0:00:23\u001b[0m\n",
            "\u001b[?25hVoila!âœ¨ Your file has been transcribed go check it out over here ğŸ‘‰ output.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head output.json"
      ],
      "metadata": {
        "id": "tBXIWHY1qVgp",
        "outputId": "efab75db-ff61-4ef0-a562-cb8dd9ef88d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"speakers\": [], \"chunks\": [{\"timestamp\": [0.52, 3.24], \"text\": \" Oi, Peter. Obrigada por responder.\"}, {\"timestamp\": [4.44, 45.12], \"text\": \" Bom, a AngÃ©lica jÃ¡ saiu do hospital, jÃ¡ consegui tirar de lÃ¡, jÃ¡ consegui remover. Agora ela estÃ¡ num processo difÃ­cil, porque ela estÃ¡ com muita sÃ­tio. Eu vou ver lÃ¡ como Ã© que estÃ£o as coisas. O Frank jÃ¡ estÃ¡ estÃ¡ pelo Loas daqui o que eu precisava era conseguir alguma coisa lÃ¡ da Alemanha algum documento dele da onde ele foi adotado pra poder conseguir ajuda como da judaica, entendeu entÃ£o isso Ã© uma das coisas que eu tÃ´ precisando ainda.\"}, {\"timestamp\": [47.08, 47.66], \"text\": \" Mas a gente vai falando, tÃ¡?\"}, {\"timestamp\": [50.46, 52.14], \"text\": \" AmanhÃ£ eu vejo tudo direitinho. Obrigada, tÃ¡?\"}, {\"timestamp\": [53.84, 55.44], \"text\": \" AngÃ©lica tÃ¡ com cÃ¢ncer.\"}, {\"timestamp\": [57.22, 57.72], \"text\": \" Quase estÃ¡ aos quatro.\"}, {\"timestamp\": [60.52, 61.06], \"text\": \" JÃ¡ tÃ¡ com a CIT, tÃ¡ com cÃ¢ncer no pÃ¢ncreas.\"}, {\"timestamp\": [64.76, 66.98], \"text\": \" ComeÃ§aram a fazer no fÃ­gado, com necrose do fÃ­gado. E fazendo a CIT, aquela barriga d'Ã¡gua, d'Ã¡gua um fÃ­gado com necrose do fÃ­gado e fazendo a CIT, aquela\"}, {\"timestamp\": [66.98, 69.18], \"text\": \" barriga d'Ã¡gua d'Ã¡gua do fÃ­gado, nÃ©?\"}, {\"timestamp\": [70.28, 73.16], \"text\": \" A coisa tÃ¡ muito grave, muito grave.\"}], \"text\": \" Oi, Peter. Obrigada por responder. Bom, a AngÃ©lica jÃ¡ saiu do hospital, jÃ¡ consegui tirar de lÃ¡, jÃ¡ consegui remover. Agora ela estÃ¡ num processo difÃ­cil, porque ela estÃ¡ com muita sÃ­tio. Eu vou ver lÃ¡ como Ã© que estÃ£o as coisas. O Frank jÃ¡ estÃ¡ estÃ¡ pelo Loas daqui o que eu precisava era conseguir alguma coisa lÃ¡ da Alemanha algum documento dele da onde ele foi adotado pra poder conseguir ajuda como da judaica, entendeu entÃ£o isso Ã© uma das coisas que eu tÃ´ precisando ainda. Mas a gente vai falando, tÃ¡? AmanhÃ£ eu vejo tudo direitinho. Obrigada, tÃ¡? AngÃ©lica tÃ¡ com cÃ¢ncer. Quase estÃ¡ aos quatro. JÃ¡ tÃ¡ com a CIT, tÃ¡ com cÃ¢ncer no pÃ¢ncreas. ComeÃ§aram a fazer no fÃ­gado, com necrose do fÃ­gado. E fazendo a CIT, aquela barriga d'Ã¡gua, d'Ã¡gua um fÃ­gado com necrose do fÃ­gado e fazendo a CIT, aquela barriga d'Ã¡gua d'Ã¡gua do fÃ­gado, nÃ©? A coisa tÃ¡ muito grave, muito grave.\"}"
          ]
        }
      ]
    }
  ]
}